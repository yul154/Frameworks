# 缓存问题
在高并发的业务场景下，数据库大多数情况都是用户并发访问最薄弱的环节。所以，就需要使用redis做一个缓冲操作，让请求先访问到redis，而不是直接访问Mysql等数据库。这样可以大大缓解数据库的压力

**当缓存库出现时，必须要考虑如下问题：**
* 缓存穿透
* 缓存穿击
* 缓存雪崩
* 缓存污染（或者满了)
* 缓存和数据库一致性

## 缓存穿透

缓存和数据库中都没有的数据，而用户不断发起请求。由于缓存是不命中时被动写的，这将导致这个不存在的数据每次请求都要到存储层去查询，失去了缓存的意义。在流量大时，可能DB就挂掉了，

**解决方案**
1.  接口层增加校验，如用户鉴权校验，id做基础校验，id<=0的直接拦截； 
2.  从缓存取不到的数据，在数据库中也没有取到，这时也可以将key-value对写为key-null，缓存有效时间可以设置短点，如30秒（设置太长会导致正常情况也没法使用）。这样可以防止攻击用户反复用同一个id暴力攻击 
3.  bloomfilter就类似于一个hash set，用于快速判某个元素是否存在于集合中，其典型的应用场景就是快速判断一个key是否存在于某容器，不存在就直接返回。布隆过滤器的关键就在于hash算法和容器大小， ¶


## 缓存击穿

缓存中没有但数据库中有的数据(一般是缓存时间到期),这时由于并发用户特别多，同时读缓存没读到数据，又同时去数据库去取数据，引起数据库压力瞬间增大，造成过大压力。

**解决方案**
1. 设置热点数据永远不过期。
2. 接口限流与熔断，降级。重要的接口一定要做好限流策略，防止用户恶意刷接口，同时要降级准备，当接口中的某些服务不可用时候，进行熔断，失败快速返回机制
3. 加互斥锁


## 缓存雪崩

数据大批量到过期时间，而查询数据量巨大，引起数据库压力过大甚至down机。和缓存击穿不同的是，缓存击穿指并发查同一条数据，缓存雪崩是不同数据都过期了，很多数据都查不到从而查数据库

**解决方案**
1. 缓存数据的过期时间设置随机，防止同一时间大量数据过期现象发生。
2. 如果缓存数据库是分布式部署，将热点数据均匀分布在不同的缓存数据库中。
3. 设置热点数据永远不过期。


## 缓存污染（或满了）

缓存中一些只会被访问一次或者几次的的数据，被访问完后，再也不会被访问到，但这部分数据依然留存在缓存中，消耗缓存空间

建议把缓存容量设置为总数据量的 15% 到 30%，兼顾访问性能和内存空间开销
```
CONFIG SET maxmemory 4gb
```

* 惰性删除：当读/写一个已经过期的key时，会触发惰性删除策略，直接删除掉这个过期key，很明显，这是被动的。
* 定期删除：由于惰性删除策略无法保证冷数据被及时删掉，所以 redis 会定期主动淘汰一批已过期的key。
* 主动删除：当前已用内存超过maxMemory限定时，触发主动清理策略。主动设置的前提是设置了maxMemory的值。

redis采用的是定期删除+惰性删除策略
* 定期删除
  * redis默认每个100ms检查，是否有过期的key,有过期key则删除
  * redis不是每个100ms将所有的key检查一次，而是随机抽取进行检查
* 惰性删除派上用场
  * 如果只采用定期删除策略，会导致很多key到时间没有删除
  * 当读/写一个已经key时，redis会检查一下，这个key如果设置了过期时间那么是否过期了？如果过期了此时就会删除
  * 如果定期删除没删除key。然后你也没即时去请求key，也就是说惰性删除也没生效。这样，redis的内存会越来越高。那么就应该采用内存淘汰机制 Redis的数据淘汰机制

当内存不足以容纳新写入数据时，
* 不淘汰
  * noeviction （v4.0后默认的） :一旦缓存被写满了，再有写请求来时，Redis 不再提供服务，而是直接返回错误
* 对设置了过期时间的数据中进行淘汰
  * 随机：volatile-random : 在设置了过期时间的键值对中，进行随机删除
  * ttl：volatile-ttl : Redis在筛选需删除的数据时，越早过期的数据越优先被选择
  * lru：volatile-lru : 使用 LRU 算法筛选设置了过期时间的键值对。 
  * lfu：volatile-lfu : 首先会根据数据的访问次数进行筛选，把访问次数最低的数据淘汰出缓存,两个数据的访问次数相同，LFU 策略再比较这两个数据的访问时效性
* 全部数据进行淘汰
  * 随机：allkeys-random 
  * lru：allkeys-lru 
  * lfu：allkeys-lfu

------

## 数据库和缓存一致性


1.缓存引入 -> 想要提高应用的性能
2.放到缓存中读取 -> 全全量数据刷到缓存中，启动一个定时任务，定时把数据库的数据，更新到缓存中 -> 不经常访问的数据，数据不一致
3. 更新数据库 + 更新缓存，更新数据库 + 删除缓存 -> 无论谁先谁后，但凡后者发生异常，就会对业务造成影响
4. 更新数据库 + 更新缓存方案 -> 并发引发的一致性问题 -> 加「分布式锁」-> 缓存资源浪费和机器性能浪费
5. 删除缓存 -> 
  *  先删除缓存,后更新数据库(第二步操作失败，数据库是最新值，缓存中是旧值) ->在「并发」场景下依旧有不一致问题 -> 「延迟双删」，但这个延迟时间很难评估
  * 先更新数据库,再删除缓存 ->当发生「读+写」并发时,数据不一致的情况(但概率很低)->异步重试-> 保证两步都成功执行->消息队列,订阅变更日志(不想在应用中去写消息队列)方案来做,本质是重试的方式保证数据最终一致
      * 读写分离 + 主从库延迟 也会导致缓存和数据库不一致 -> 缓解此问题的方案是「延迟双删」，凭借经验发送「延迟消息」到队列中
7. 保证第二步成功执行，就是解决问题的关键 -> 异步重试 -> 把重试请求写到「消息队列」中(成功消费之前不会丢失,消息队列保证消息成功投递)



一致性问题是分布式常见问题，还可以再分为最终一致性和强一致性
* 强一致性对于关系型数据库，要求更新过的数据能被后续的访问都能看到，
* 弱一致性： 能容忍后续的部分或者全部访问不到。
* 最终一致性：如果经过一段时间后要求能访问到更新后的数据





> 如果对数据有强一致性要求，不能放缓存。只能说降低不一致发生的概率，无法完全避免


不管是先写MySQL数据库，再删除Redis缓存；还是先删除缓存，再写库，都有可能出现数据不一致的情况
* 如果删除了缓存Redis，还没有来得及写库MySQL，另一个线程就来读取，发现缓存为空，则去数据库中读取数据写入缓存，此时缓存中为脏数据。
* 如果先写了库，在删除缓存前，写库的线程宕机了，没有删除掉缓存，则也会出现数据不一致情况。

### 4种相关模式

Cache-Aside Pattern，即旁路缓存模式，
* 读的时候，先读缓存，缓存命中的话，直接返回数据,没有命中的话，就去读数据库，从数据库取出数据，放入缓存后，同时返回响应。
* 更新的时候，先更新数据库，然后再删除缓存。

Read-Through/Write-Through（读写穿透）
* 从缓存读取数据，读到直接返回 ,如果读取不到的话，从数据库加载，写入缓存后，再返回响应。
* 当发生写请求时，也是由缓存抽象层完成数据源和缓存数据的更新

Write-behind （异步缓存写入）
* 都是由Cache Provider来负责缓存和数据库的读写。
* 它们又有个很大的不同：Read/Write-Through是同步更新缓存和数据的
* Write-Behind则是只更新缓存，不直接更新数据库，通过批量异步的方式来更新数据库
* InnoDB Buffer Pool机制就使用到这种模式


### 方案0 延时双删策略
* 先更新数据库，再删除缓存方案 -> 缓存都被回种了「旧值」
* 读写分离 + 主从复制延迟 -> 缓存都被回种了「旧值

在写库前后都进行redis.del(key)操作，并且设定合理的超时时间
```
public void write(String key,Object data)
{ 
    redis.delKey(key); 
    db.updateData(data); 
    Thread.sleep(500); 
    redis.delKey(key); 
}
```

1. 先删除缓存
2. 再更新数据库
3. 休眠一会（比如1秒）->  就是确保读请求结束，写请求可以删除读请求造成的缓存脏数据
4. 再次删除缓存。第二次删除缓存失败 -> 给Key设置一个自然的expire过期时间，让它自动过期

> 延迟时间到底设置要多久呢？
* 延迟时间要大于「主从复制」的延迟时间
* 延迟时间要大于线程 B 读取数据库 + 写入缓存的时间


结合双删策略+缓存超时设置，这样最差的情况就是在超时时间内数据存在不一致，而且又增加了写请求的耗时。

### 方案1 先更新数据库，再删除缓存」方案，并配合「消息队列」或「订阅变更日志」的方式来做

<img width="558" alt="Screen Shot 2021-12-07 at 12 11 26 AM" src="https://user-images.githubusercontent.com/27160394/144881051-100327e2-10e2-4cad-8326-8e650ae7df02.png">

* 更新数据库数据；
* 缓存因为种种问题删除失败
* 将需要删除的key发送至消息队列
* 自己消费消息，获得需要删除的key
* 继续重试删除操作，直到成功

该方案有一个缺点，对业务线代码造成大量的侵入

### 方案2 先更新数据库，再删除缓存 +  异步更新缓存(基于订阅binlog的同步机制)

MySQL binlog增量订阅消费+消息队列+增量数据更新到redis 
1. 读Redis：热数据基本都在Redis 
2. 写MySQL: 增删改都是操作MySQL 
3. 更新Redis数据：MySQ的数据操作binlog，来更新到Redis

读取binlog后分析 ，利用消息队列,推送更新各台的redis缓存数据。
* 这样一旦MySQL中产生了新的写入、更新、删除等操作，就可以把binlog相关的消息推送至Redis，
* Redis再根据binlog中的记录，对Redis进行更新。
* 订阅程序提取出所需要的数据以及key
* 另起一段非业务代码，获得该信息
* 尝试删除缓存操作，发现删除失败
* 将这些信息发送至消息队列
* 重新从消息队列中获得该数据，重试操作


