# 主从复制
> 避免单点故障，即保证高可用，便需要冗余（副本）方式提供集群服务。而Redis 提供了主从库模式，以保证数据副本的一致

主从复制，是指将一台Redis服务器的数据，复制到其他的Redis服务器。前者称为主节点(master)，后者称为从节点(slave)；数据的复制是单向的，只能由主节点到从节点。

主从复制的作用
* 数据冗余：主从复制实现了数据的热备份，是持久化之外的一种数据冗余方式。
* 故障恢复：当主节点出现问题时，可以由从节点提供服务，实现快速的故障恢复；实际上是一种服务的冗余。
* 负载均衡：在主从复制的基础上，配合读写分离，可以由主节点提供写服务，由从节点提供读服务，分担服务器负载；尤其是在写少读多的场景下，通过多个从节点分担读负载，可以大大提高Redis服务器的并发量。
* 高可用基石：除了上述作用以外，主从复制还是哨兵和集群能够实施的基础，因此说主从复制是Redis高可用的基础。


主从库之间采用的是读写分离的方式。
* 读操作：主库、从库都可以接收；
* 写操作：首先到主库执行，然后，主库将写操作同步给从库。


## 主从复制原理
* 全量（同步）复制：比如第一次同步时(2.8版本之前只有全量复制)
* 增量（同步）复制：只会把主从库网络断连期间主库收到的命令，同步给从库

### 全量复制
> 通过 replicaof（Redis 5.0 之前使用 slaveof）命令形成主库和从库的关系

1. 确立主从关系
```
replicaof 172.16.19.3 6379 //
```
2. 主从库间建立连接、协商同步的过程
  *  从库给主库发送`psync`命令，表示要进行数据同步，主库根据这个命令的参数来启动复制。
  *  `psync` 命令包含了主库的`runID`和复制进度`offset`两个参数。
      *  runID，是每个 Redis 实例启动时都会自动生成的一个随机 ID，用来唯一标记这个实例。当从库和主库第一次复制时，因为不知道主库的 runID，所以将 runID 设为“？”。
      *  offset，此时设为 -1，表示第一次复制
  * 主库收到`psync`命令后，会用`FULLRESYNC`响应命令带上两个参数：主库 runID 和主库目前的复制进度 offset，返回给从库
  * 从库收到响应后，会记录下这两个参数。这里有个地方需要注意，FULLRESYNC 响应表示第一次复制采用的全量复制，也就是说，主库会把当前所有的数据都复制给从库

3.主库将所有数据同步给从库
  * 从库收到数据后，在本地完成数据加载。
  * 这个过程依赖于内存快照生成的 RDB 文件
  * 主库执行`bgsave`命令，生成`RDB`文件，接着将文件发给从库
  * 从库接收到`RDB`文件后，会先清空当前数据库，然后加载`RDB`文件。这是因为从库在通过 replicaof 命令开始和主库同步前，可能保存了其他数据
  * 主库将数据同步给从库的过程中，主库不会被阻塞，仍然可以正常接收请求. 否则，Redis 的服务就被中断
    * 这些请求中的写操作并没有记录到刚刚生成的 RDB 文件中。为了保证主从库的数据一致性，主库会在内存中用专门的 replication buffer，记录RDB文件生成后收到的所有写操作

4.主库会把第二阶段执行过程中新收到的写命令，再发送给从库
  * 当主库完成RDB文件发送后，就会把此时 replication buffer 中的修改操作发给从库，从库再重新执行这些操作

<img width="675" alt="Screen Shot 2021-12-07 at 10 53 27 PM" src="https://user-images.githubusercontent.com/27160394/145051813-81c8abc2-b8c7-405a-ae41-8f15d8608ee7.png">


### 增量复制
> 如果主从库在命令传播时出现了网络闪断，那么，从库就会和主库重新进行一次全量复制，开销非常大

`replication buffer` : Redis都需要给分配一个内存buffer进行数据交互,
* Redis先把数据写到这个buffer中，然后再把buffer中的数据发到client socket中再通过网络发送出去
* 从库作为一个client，也会分配一个buffer，只不过这个buffer专门用来传播用户的写命令到从库，保证主从数据一致

`repl_backlog_buffer` : 它是为了从库断开之后,找到主从差异数据而设计的环形缓冲区,从而避免全量复制带来的性能开销
* 如果从库断开时间太久，repl_backlog_buffer环形缓冲区被主库的写命令覆盖了，那么从库连上主库后只能乖乖地进行一次全量复制
* repl_backlog_buffer配置尽量大一些，可以降低主从断开后全量复制的概率

<img width="569" alt="Screen Shot 2021-12-07 at 10 54 17 PM" src="https://user-images.githubusercontent.com/27160394/145051953-956be16c-68bc-4280-90cf-778a262dc03f.png">

> 如果在网络断开期间，repl_backlog_size环形缓冲区写满之后，从库是会丢失掉那部分被覆盖掉的数据，还是直接进行全量复制呢？

* 一个从库如果和主库断连时间过长，造成它在主库repl_backlog_buffer的slave_repl_offset位置上的数据已经被覆盖掉了，此时从库和主库间将进行全量复制。
* 每个从库会记录自己的slave_repl_offset，每个从库的复制进度也不一定相同。在和主库重连进行恢复时，从库会通过psync命令把自己记录的slave_repl_offset发给主库，主库会根据从库各自的复制进度，来决定这个从库可以进行增量复制，还是全量复制



#### 当主服务器不进行持久化时复制的安全性

> 在进行主从复制设置时，强烈建议在主服务器上开启持久化，当不能这么做时，比如考虑到延迟的问题，应该将实例配置为避免自动重启

* 我们设置节点A为主服务器，关闭持久化，节点B和C从节点A复制数据。 
* 这时出现了一个崩溃，但Redis具有自动重启系统，重启了进程，因为关闭了持久化，节点重启后只有一个空的数据集。 
* 节点B和C从节点A进行复制，现在节点A是空的，所以节点B和C上的复制数据也会被删除。
* 当在高可用系统中使用Redis Sentinel，关闭了主服务器的持久化，并且允许自动重启，这种情况是很危险的。比如主服务器可能在很短的时间就完成了重启，以至于Sentinel都无法检测到这次失败

#### 为什么主从全量复制使用RDB而不使用AOF？
* 文件大小：RDB文件内容是经过压缩的二进制数据，文件很小。而AOF文件记录的是每一次写操作的命令，写操作越多文件会变得很大。在主从全量数据同步时，传输RDB文件可以尽量降低对主库机器网络带宽的消耗，从库在加载RDB文件时，
* 效率： RDB文件存储的都是二进制数据，从库直接按照RDB协议解析还原数据即可，速度会非常快，而AOF需要依次重放每个写命令，这个过程会经历冗长的处理逻辑，恢复速度相比RDB会慢得多，
* 刷盘和备份策略：假设要使用AOF做全量复制，意味着必须打开AOF功能，打开AOF就要选择文件刷盘的策略，选择不当会严重影响Redis性能。而RDB只有在需要定时备份和主从全量复制数据时才会触发生成一次快照

#### 为什么还有无磁盘复制模式？

如果使用比较低速的磁盘，这种操作会给主服务器带来较大的压力

无磁盘复制模式：master创建一个新进程直接dump RDB到slave的socket，不经过主进程，不经过硬盘。适用于disk较慢，并且网络较快的时候

`repl-diskless-sync`:配置参数来启动无磁盘复制

`repl-diskless-sync-delay` 参数来配置传输开始的延迟时间；master等待一个repl-diskless-sync-delay的秒数，如果没slave来的话，就直接传，后来的得排队等了; 否则就可以一起传。

#### 为什么还会有从库的从库的设计？

如果从库数量很多，而且都要和主库进行全量复制的话，就会导致主库忙于 fork 子进程生成 RDB 文件，进行数据全量复制。fork 这个操作会阻塞主线程处理正常请求，从而导致主库响应应用程序的请求速度变慢

* 主 - 从 - 从”模式。
* 将主库生成 RDB 和传输 RDB 的压力，以级联的方式分散到从库上
* 手动选择一个从用于级联其他的从库。然后，我们可以再选择一些从库（例如三分之一的从库），在这些从库上执行如下命令，让它们和刚才所选的从库，建立起主从关系

<img width="568" alt="Screen Shot 2021-12-07 at 11 09 49 PM" src="https://user-images.githubusercontent.com/27160394/145054685-e63bbc1a-ec47-40a4-81ae-fa52dfe9177d.png">


### 读写分离及其中的问题

延迟与不一致问题
* 优化主从节点之间的网络环境
* 监控主从节点延迟（通过offset）判断，如果从节点延迟过大，通知应用不再通过该从节点读取数据
* 使用集群同时扩展写负载和读负载等

数据过期问题
* 在主从复制场景下，为了主从节点的数据一致性，从节点不会主动删除数据，而是由主节点控制从节点中过期数据的删除。
* 由于主节点的惰性删除和定期删除策略，都不能保证主节点及时对过期数据执行删除操作，因此，当客户端通过Redis从节点读取数据时，很容易读取到已经过期的数据。
* 从节点在读取数据时，增加了对数据是否过期的判断：如果该数据已过期，则不返回给客户端












